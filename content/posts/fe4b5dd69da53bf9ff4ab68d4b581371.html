+++
title = "卡巴斯基发现有3000篇暗网帖子讨论如何滥用ChatGPT和LLM等人工智能工具"
date = 2024-01-28T08:52:38+08:00
categories = ["暗网纵论"]
tags = ["ChatGPT", "LLM", "OpenAI", "人工智能", "卡巴斯基"]
thumbnail = ""
+++

<div class="entry-content clearfix">
<div class="wp-block-image">
<figure class="aligncenter size-full"><noscript><img fetchpriority="high" decoding="async" width="860" height="600" src="/images/79ca3872e16a2d70d280c5fddce8064c.webp" alt="卡巴斯基发现有3000篇暗网帖子讨论如何滥用ChatGPT和LLM等人工智能工具" class="wp-image-3090"></noscript><img fetchpriority="high" decoding="async" width="860" height="600" src="/images/79ca3872e16a2d70d280c5fddce8064c.webp" alt="卡巴斯基发现有3000篇暗网帖子讨论如何滥用ChatGPT和LLM等人工智能工具" class="wp-image-3090 j-lazy"></figure></div>
<p><span class="wpcom_tag_link">卡巴斯基</span>数字足迹情报服务近日<a href="https://dfi.kaspersky.com/blog/ai-in-darknet" target="_blank" rel="noreferrer noopener">发布的一份报告</a>发现，在2023年，有近3000个暗网帖子在讨论如何使用<span class="wpcom_tag_link">ChatGPT</span>和其他大型语言模型（<span class="wpcom_tag_link">LLM</span>）进行非法活动。</p>
<p>这些讨论包括创建聊天机器人的恶意替代品、越狱（突破语言设置的恶意使用限制）技术、恶意提示列表以及有关如何滥用这些工具的其他一般对话，以及讨论可访问ChatGPT付费版本的被盗帐户的帖子。</p>
<h2 class="wp-block-heading">主要见解</h2>
<p>卡巴斯基的数字足迹情报服务在2023年发现了近3000个暗网帖子，讨论涉及ChatGPT和其他大型语言模型（LLM）的非法活动。</p>
<p>其中包括创建恶意版本、越狱技术、有害提示列表以及有关被盗帐户的讨论。</p>
<p>暗网上的威胁参与者积极分享有关利用ChatGPT的知识，讨论创建恶意软件、使用<span class="wpcom_tag_link">人工智能</span>处理用户数据转储以及共享越狱以绕过内容审核策略等主题。</p>
<p>研究还发现，围绕WormGPT、XXXGPT和FraudGPT等工具进行了大量讨论，这些工具被作为ChatGPT的替代品销售，限制较少。</p>
<p>卡巴斯基的研究发布前不久，<span class="wpcom_tag_link">OpenAI</span>暂停了一名开发者的资格，原因是他创建了一个模仿美国国会议员迪恩·飞利浦（DeanPhilips）的聊天机器人。该组织表示，这一行为违反了其关于政治竞选或未经同意冒充个人的规则。</p>
<h2 class="wp-block-heading">ChatGPT如何被利用？主要发现</h2>
<p>虽然企业和消费者将ChatGPT作为改善日常生活的工具，但威胁行为者正在尝试利用它来攻击毫无戒心的个人和组织。</p>
<p>在随附的研究博客上分享的一系列帖子中，可以看到暗网用户讨论如何使用GPT创建可以修改其代码的多态恶意软件，以及如何使用人工智能（AI）处理用户数据转储。</p>
<p>另一位用户分享了著名的ChatGPT的“Do Anything Now“（DAN）越狱，旨在绕过OpenAI的内容审核政策。研究发现，在2023年，暗网上有249项分发和销售提示信息的提议。</p>
<p>总的来说，这些发现不仅凸显了ChatGPT可能被滥用，而且还表明网络犯罪分子正在积极分享如何利用它的知识。正如一位匿名用户评论的那样，“AI帮了我很多，GPT-4是我最好的朋友。”</p>
<p>卡巴斯基数字足迹分析师阿丽萨·库利申科（Alisa Kulishenko）表示：“威胁行为者正在积极探索实施ChatGPT和人工智能的各种方案。”</p>
<p>“主题通常包括恶意软件的开发和其他类型的非法使用语言模型，例如处理被盗用户数据、解析受感染设备中的文件等。</p>
<p>“人工智能工具的普及导致ChatGPT或其同类工具的自动响应被集成到一些网络犯罪论坛中。”</p>
<p>“此外，威胁行为者倾向于通过各种暗网渠道分享越狱信息（可以解锁附加功能的特殊提示集），并设计出利用基于模型的合法工具的方法，例如基于恶意目的模型的渗透测试工具。”</p>
<h2 class="wp-block-heading">到目前为止有什么风险？</h2>
<p>虽然库里申科认为“生成式人工智能和聊天机器人不太可能彻底改变攻击格局”，但这项研究表明，威胁行为者对利用这项技术达到自己的目的产生了浓厚的兴趣。</p>
<p>到目前为止，生成式技术最大的风险似乎来自于他们创建网络钓鱼电子邮件的能力。例如，网络安全供应商SlashNext于2023年11月发布的一项研究发现，自2022年第四季度ChatGPT发布以来，恶意网络钓鱼电子邮件增加了1265%。</p>
<p>尽管OpenAI等供应商已尝试使用内容审核策略来阻止ChatGPT产生恶意输出，但事实证明这些策略不足以防止滥用，而且很容易通过越狱和其他技术来规避。</p>
<p>简要测试下ChatGPT的内容审核功能，要求ChatGPT生成一封网络钓鱼电子邮件，“作为网络钓鱼防范意识计划的一部分”，通过该电子邮件可以说服收件人更新其在线帐户支付详细信息，聊天机器人对此做出了回应，生成了一封基本的钓鱼邮件。</p>
<p>现实情况是，如果有人想恶意使用LLM，他们有很多变通办法可以做到这一点。</p>
<h2 class="wp-block-heading">底线</h2>
<p>该研究强调，暗网正热衷于使用人工智能来自动化网络攻击。尽管不必惊慌，但必须认识到网络犯罪有可能增加。</p>
<p>如果黑客论坛和其他地下社区继续就如何恶意使用这项技术进行合作，网络犯罪将不可避免地增加。</p>
<p>如今，人工智能初创公司已超过67000家，谁知道这条崎岖的道路将会把人类带向何方？</p>
 </div>